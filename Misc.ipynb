{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection of tried methods and commands\n",
    "\n",
    "\n",
    "##### CUDA GPU installation confirmation, extensive setup tested for potential better image processing but GPU memory proved insufficient and led to frequent crashes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.test.is_built_with_cuda()) \n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First simple CNN model adding layers from scratch to get benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - ETA: 0s - loss: 2.8402 - accuracy: 0.0743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ShwetankPC\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\PIL\\Image.py:2847: DecompressionBombWarning: Image size (95799284 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 683s 4s/step - loss: 2.8402 - accuracy: 0.0743 - val_loss: 4.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 580s 3s/step - loss: 2.6567 - accuracy: 0.1128 - val_loss: 5.9962 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 580s 3s/step - loss: 2.6065 - accuracy: 0.1330 - val_loss: 6.7849 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 575s 3s/step - loss: 2.5572 - accuracy: 0.1511 - val_loss: 7.8191 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 578s 3s/step - loss: 2.4925 - accuracy: 0.1824 - val_loss: 8.5285 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223cefcaeb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "          epochs=5,\n",
    "          validation_data=validation_generator)          \n",
    "#validation_data=validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the validation accuracy is showing as zero because the validation set had not been properly shuffled before split and so none of its classes were being recognized. However, the training accuracy could still be used to compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator,\n",
    "          epochs=5,\n",
    "          validation_data=validation_generator)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 420s 2s/step - loss: 2.4452 - accuracy: 0.2081\n",
      "Test loss: 2.4452273845672607\n",
      "Test accuracy: 0.20805548131465912\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(train_generator, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decent test accuracy and the model could certainly be kept going for training, however, other pre-trained methods seemed to rise faster in accuracy.\n",
    "\n",
    "##### Art style classification first attempt with ResNet (using flatten and two ReLu layers instead of the two better performing pooling layers used in 'Capstone_StyleClassification' notebook): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50V2 \n",
    "\n",
    "model2 = ResNet50V2 (weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(height,width,3))\n",
    "\n",
    "for layer in model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "    # Add our own layers to the end of the network\n",
    "x = model2.output \n",
    "x = Flatten()(x) \n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model2 = Model(inputs=model2.input, \n",
    "              outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "263/263 [==============================] - 1051s 4s/step - loss: 3.0618 - accuracy: 0.1495 - val_loss: 5.3718 - val_accuracy: 0.0031\n",
      "Epoch 2/2\n",
      "263/263 [==============================] - 954s 4s/step - loss: 2.4606 - accuracy: 0.2125 - val_loss: 7.4308 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223e382cc10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model2.fit(train_generator,\n",
    "          epochs=2,\n",
    "          #validation_split = 0.25,\n",
    "          validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy rises much faster than from scratch model above but was slower than the Xception model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup for NASNetMobile (mobile version having very few parameters), while producing decent accuracy gains, it was slower than Xception and ResNet and so was abandoned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
      "19996672/19993432 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import NASNetMobile \n",
    "\n",
    "model2 = NASNetMobile (weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(height,width,3))\n",
    "\n",
    "for layer in model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    # Add our own layers to the end of the network\n",
    "x = model2.output \n",
    "x = Flatten()(x) \n",
    "x = Dense(500, activation='relu')(x)\n",
    "#x = Dense(150, activation='relu')(x)\n",
    "output = Dense(126, activation='softmax')(x)\n",
    "\n",
    "model2 = Model(inputs=model2.input, \n",
    "              outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "256/256 [==============================] - ETA: 0s - loss: 4.7792 - accuracy: 0.1623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ShwetankPC\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\PIL\\Image.py:2847: DecompressionBombWarning: Image size (107327830 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 460s 2s/step - loss: 4.7792 - accuracy: 0.1623 - val_loss: 3.3927 - val_accuracy: 0.1799\n",
      "Epoch 2/5\n",
      "256/256 [==============================] - 430s 2s/step - loss: 2.7140 - accuracy: 0.2897 - val_loss: 3.4230 - val_accuracy: 0.1774\n",
      "Epoch 3/5\n",
      "256/256 [==============================] - ETA: 0s - loss: 2.2148 - accuracy: 0.3917"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Use an early stopping callback to stop training\n",
    "# once we no longer have improvements in our validation loss\n",
    "model2.fit(train_generator,\n",
    "          epochs=5,\n",
    "          #validation_split = 0.25,\n",
    "          validation_data=validation_generator,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup for EfficientNetB0 testing, results were deleted during course of trial and error, remained very low below 10% for first 6 epochs and so was abandoned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    \n",
    "modelb = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(height,width,3))\n",
    "    # Freeze the pretrained weights\n",
    "modelb.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(modelb.output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.2\n",
    "x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "x = Flatten()(x) \n",
    "#x = Dense(1000, activation='relu')(x)\n",
    "x = Dense(400, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "modelb = Model(modelb.input, outputs, name=\"EfficientNet\")\n",
    "optimizer = Adam(learning_rate=1e-2)\n",
    "modelb.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # @param {type: \"slider\", min:8, max:80}\n",
    "hist = modelb.fit(train_generator, epochs=epochs, validation_data=validation_generator, verbose=1)\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demonstration of loading a model testing accuracy on test dataset where it works, not sure why it works here but did not in 'Captstone_ArtistClassification' file when doing same for VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model('D:\\Documents\\BrainStation\\Capstone\\Res_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18697 validated image filenames belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "testpath = r'D:\\Documents\\BrainStation\\Capstone\\test\\test\\\\'\n",
    "\n",
    "#train_limit=int(len(samples)*0.75)\n",
    "test_gen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "height=224\n",
    "width=224\n",
    "\n",
    "test_generator=test_gen.flow_from_dataframe(\n",
    "dataframe=dftest,\n",
    "directory=testpath,\n",
    "x_col=\"new_filename\",\n",
    "y_col=\"style\",\n",
    "#subset=\"validation\",\n",
    "color_mode='rgb',\n",
    "batch_size=40,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(height,width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 1097s 2s/step - loss: 2.5165 - top_k_categorical_accuracy: 0.5859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5164759159088135, 0.58592289686203]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "testmodel= Model(inputs=model.input, \n",
    "              outputs=model.output)\n",
    "\n",
    "metric = TopKCategoricalAccuracy(k=3)\n",
    "testmodel.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metric)\n",
    "\n",
    "testmodel.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some of the operations carried out to reduce number of style classes and possibly increase accuracy (did not have any significant effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['style'].replace('Post-Impressionism', 'Impressionism', inplace=True)     #Combine two styles together\n",
    "df['style'].replace('Mannerism (Late Renaissance)', 'Renaissance', inplace=True)\n",
    "df['style'].replace('Early Renaissance', 'Renaissance', inplace=True)\n",
    "df['style'].replace('High Renaissance', 'Renaissance', inplace=True)\n",
    "df['style'].replace('Northern Renaissance', 'Renaissance', inplace=True)\n",
    "df['style'].replace('Academicism', 'Neoclassicism', inplace=True\n",
    "                    \n",
    "styles=styles.drop(['Art Informel', 'Abstract Expressionism', 'Abstract Art', 'Color Field Painting'])`     #Drop abstract type art "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
